{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import sys,copy\n",
    "\n",
    "# stage1 clip sam merge \n",
    "# used for stage2 \n",
    "\n",
    "sam_path =  \"/data/xcg/lavis_data/output/BLIP2/Final/BLIP2&SAM_LONG_coco&roco&medi/sam_after_coco_med.pth\"\n",
    "clip_path = \"/home/xcg/.cache/torch/hub/checkpoints/blip2_pretrained.pth\"\n",
    "bad_list = [\"query_tokens\", \"temp\", \"vision_proj.weight\", \"vision_proj.bias\", \"text_proj.weight\", \"text_proj.bias\", \"itm_head.weight\", \"itm_head.bias\"]\n",
    "outpath = \"/data/xcg/lavis_data/output/BLIP2/Final/BLIP2&SAM_LONG_coco&roco&medi_noclip/stage1_concat.pth\" \n",
    "\n",
    "sam = torch.load(sam_path, map_location='cpu') \n",
    "clip = torch.load(clip_path, map_location='cpu') \n",
    "sam_dict = sam[\"model\"] \n",
    "clip_dict = clip[\"model\"] \n",
    "\n",
    "output = copy.deepcopy(clip)\n",
    "for key in list(sam_dict.keys()):\n",
    "    if key.startswith(\"sam_Qformer.\") or key == \"sam_query_tokens\":\n",
    "        output[\"model\"][key] = sam_dict[key]\n",
    "\n",
    "for key in list(output[\"model\"].keys()):\n",
    "    print(key)\n",
    "\n",
    "torch.save(output,outpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,copy\n",
    "fucklist = ['Qformer.bert.encoder.layer.0.intermediate.dense.weight', 'Qformer.bert.encoder.layer.0.intermediate.dense.bias', 'Qformer.bert.encoder.layer.0.output.dense.weight', 'Qformer.bert.encoder.layer.0.output.dense.bias', 'Qformer.bert.encoder.layer.0.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.0.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.1.intermediate.dense.weight', 'Qformer.bert.encoder.layer.1.intermediate.dense.bias', 'Qformer.bert.encoder.layer.1.output.dense.weight', 'Qformer.bert.encoder.layer.1.output.dense.bias', 'Qformer.bert.encoder.layer.1.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.1.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.2.intermediate.dense.weight', 'Qformer.bert.encoder.layer.2.intermediate.dense.bias', 'Qformer.bert.encoder.layer.2.output.dense.weight', 'Qformer.bert.encoder.layer.2.output.dense.bias', 'Qformer.bert.encoder.layer.2.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.2.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.3.intermediate.dense.weight', 'Qformer.bert.encoder.layer.3.intermediate.dense.bias', 'Qformer.bert.encoder.layer.3.output.dense.weight', 'Qformer.bert.encoder.layer.3.output.dense.bias', 'Qformer.bert.encoder.layer.3.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.3.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.4.intermediate.dense.weight', 'Qformer.bert.encoder.layer.4.intermediate.dense.bias', 'Qformer.bert.encoder.layer.4.output.dense.weight', 'Qformer.bert.encoder.layer.4.output.dense.bias', 'Qformer.bert.encoder.layer.4.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.4.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.5.intermediate.dense.weight', 'Qformer.bert.encoder.layer.5.intermediate.dense.bias', 'Qformer.bert.encoder.layer.5.output.dense.weight', 'Qformer.bert.encoder.layer.5.output.dense.bias', 'Qformer.bert.encoder.layer.5.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.5.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.6.intermediate.dense.weight', 'Qformer.bert.encoder.layer.6.intermediate.dense.bias', 'Qformer.bert.encoder.layer.6.output.dense.weight', 'Qformer.bert.encoder.layer.6.output.dense.bias', 'Qformer.bert.encoder.layer.6.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.6.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.7.intermediate.dense.weight', 'Qformer.bert.encoder.layer.7.intermediate.dense.bias', 'Qformer.bert.encoder.layer.7.output.dense.weight', 'Qformer.bert.encoder.layer.7.output.dense.bias', 'Qformer.bert.encoder.layer.7.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.7.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.8.intermediate.dense.weight', 'Qformer.bert.encoder.layer.8.intermediate.dense.bias', 'Qformer.bert.encoder.layer.8.output.dense.weight', 'Qformer.bert.encoder.layer.8.output.dense.bias', 'Qformer.bert.encoder.layer.8.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.8.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.9.intermediate.dense.weight', 'Qformer.bert.encoder.layer.9.intermediate.dense.bias', 'Qformer.bert.encoder.layer.9.output.dense.weight', 'Qformer.bert.encoder.layer.9.output.dense.bias', 'Qformer.bert.encoder.layer.9.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.9.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.10.intermediate.dense.weight', 'Qformer.bert.encoder.layer.10.intermediate.dense.bias', 'Qformer.bert.encoder.layer.10.output.dense.weight', 'Qformer.bert.encoder.layer.10.output.dense.bias', 'Qformer.bert.encoder.layer.10.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.10.output.LayerNorm.bias', 'Qformer.bert.encoder.layer.11.intermediate.dense.weight', 'Qformer.bert.encoder.layer.11.intermediate.dense.bias', 'Qformer.bert.encoder.layer.11.output.dense.weight', 'Qformer.bert.encoder.layer.11.output.dense.bias', 'Qformer.bert.encoder.layer.11.output.LayerNorm.weight', 'Qformer.bert.encoder.layer.11.output.LayerNorm.bias']\n",
    "fucklist1 = ['sam_Qformer.bert.encoder.layer.0.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.0.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.0.output.dense.weight', 'sam_Qformer.bert.encoder.layer.0.output.dense.bias', 'sam_Qformer.bert.encoder.layer.0.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.0.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.1.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.1.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.1.output.dense.weight', 'sam_Qformer.bert.encoder.layer.1.output.dense.bias', 'sam_Qformer.bert.encoder.layer.1.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.1.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.2.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.2.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.2.output.dense.weight', 'sam_Qformer.bert.encoder.layer.2.output.dense.bias', 'sam_Qformer.bert.encoder.layer.2.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.2.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.3.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.3.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.3.output.dense.weight', 'sam_Qformer.bert.encoder.layer.3.output.dense.bias', 'sam_Qformer.bert.encoder.layer.3.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.3.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.4.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.4.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.4.output.dense.weight', 'sam_Qformer.bert.encoder.layer.4.output.dense.bias', 'sam_Qformer.bert.encoder.layer.4.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.4.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.5.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.5.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.5.output.dense.weight', 'sam_Qformer.bert.encoder.layer.5.output.dense.bias', 'sam_Qformer.bert.encoder.layer.5.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.5.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.6.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.6.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.6.output.dense.weight', 'sam_Qformer.bert.encoder.layer.6.output.dense.bias', 'sam_Qformer.bert.encoder.layer.6.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.6.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.7.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.7.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.7.output.dense.weight', 'sam_Qformer.bert.encoder.layer.7.output.dense.bias', 'sam_Qformer.bert.encoder.layer.7.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.7.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.8.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.8.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.8.output.dense.weight', 'sam_Qformer.bert.encoder.layer.8.output.dense.bias', 'sam_Qformer.bert.encoder.layer.8.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.8.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.9.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.9.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.9.output.dense.weight', 'sam_Qformer.bert.encoder.layer.9.output.dense.bias', 'sam_Qformer.bert.encoder.layer.9.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.9.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.10.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.10.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.10.output.dense.weight', 'sam_Qformer.bert.encoder.layer.10.output.dense.bias', 'sam_Qformer.bert.encoder.layer.10.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.10.output.LayerNorm.bias', 'sam_Qformer.bert.encoder.layer.11.intermediate.dense.weight', 'sam_Qformer.bert.encoder.layer.11.intermediate.dense.bias', 'sam_Qformer.bert.encoder.layer.11.output.dense.weight', 'sam_Qformer.bert.encoder.layer.11.output.dense.bias', 'sam_Qformer.bert.encoder.layer.11.output.LayerNorm.weight', 'sam_Qformer.bert.encoder.layer.11.output.LayerNorm.bias']\n",
    "stage1path = \"/mnt/sdd/xcg_data/lavis_data/output/BLIP2/Final/BLIP2&SAM_coco&roco&medi/stage1_sam&clip_concat.pth\"\n",
    "stage2path = \"/mnt/sdd/xcg_data/lavis_data/output/BLIP2/Final/BLIP2&SAM_coco&roco&medi/stage2_out.pth\"\n",
    "outpath = \"/mnt/sdd/xcg_data/lavis_data/output/BLIP2/Final/BLIP2&SAM_coco&roco&medi/stage2_2generate.pth\"\n",
    "\n",
    "stage1 = torch.load(stage1path,map_location=\"cpu\")\n",
    "stage2 = torch.load(stage2path,map_location=\"cpu\")\n",
    "\n",
    "output = copy.deepcopy(stage2)\n",
    "\n",
    "for key in stage1[\"model\"]:\n",
    "    # print(key)\n",
    "    if key.startswith(\"Qformer.cls.\") or key.startswith(\"Qformer.bert.embeddings.word_embeddings\") or key.startswith(\"Qformer.bert.embeddings.position_embeddings\") or key in fucklist or key.startswith(\"sam_Qformer.cls.\") or key.startswith(\"sam_Qformer.bert.embeddings.word_embeddings\") or key.startswith(\"sam_Qformer.bert.embeddings.position_embeddings\") or key in fucklist1:\n",
    "        print(key)\n",
    "        output[\"model\"][key] = stage1[\"model\"][key]\n",
    "        \n",
    "torch.save(output,outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "pth_path =  \"/home/xcg/.cache/torch/hub/checkpoints/blip2_pretrained_opt2.7b.pth\"\n",
    "# bad_list = [\"query_tokens\", \"temp\", \"vision_proj.weight\", \"vision_proj.bias\", \"text_proj.weight\", \"text_proj.bias\", \"itm_head.weight\", \"itm_head.bias\"]\n",
    "pth = \"/mnt/sdd/xcg_data/lavis_data/output/BLIP2_CLIP/Pretrain_stage2/stage2_roco&medicat/checkpoint_2.pth\"\n",
    "\n",
    "\n",
    "checkpoint = torch.load(pth_path, map_location='cpu') \n",
    "state_dict_std = checkpoint[\"model\"]\n",
    "checkpoint2 = torch.load(pth, map_location='cpu')\n",
    "state_dict_ours = checkpoint2[\"model\"]\n",
    "for key in list(state_dict_std.keys()):\n",
    "    if key not in state_dict_ours:\n",
    "        print(key)\n",
    "print(\"-------------------------------------------------\")\n",
    "for key in list(state_dict_ours.keys()):\n",
    "    if key not in state_dict_std:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "pth_path =  \"./SAM/sam_stage1_coco_medi.pth\"\n",
    "bad_list = [\"query_tokens\", \"temp\", \"vision_proj.weight\", \"vision_proj.bias\", \"text_proj.weight\", \"text_proj.bias\", \"itm_head.weight\", \"itm_head.bias\"]\n",
    "\n",
    "\n",
    "checkpoint = torch.load(pth_path, map_location='cpu') \n",
    "state_dict = checkpoint[\"model\"] \n",
    "for key in list(state_dict.keys()):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f4464f06ef0597b7c49492ab8cd3c1489b9ed9c91f07943a71a3276c6a443e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
